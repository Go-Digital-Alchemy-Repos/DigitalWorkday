PUBLISH UNBLOCK + HOTSPOT FIX SPRINT
NON-DESTRUCTIVE • DIAGNOSTIC-FIRST • THEN SAFE FIXES

Context: Replit publish is failing after recent changes. Current logs show repeated slow GET /unread-count (200, ~340–460ms) and a POST /timer/start 409. Those are not direct publish errors, so we must locate the true publish/build failure signal first (build, start, health checks, port binding, memory, migrations).

HARD RULES
- Do NOT do broad refactors.
- Do NOT change API response shapes in breaking ways.
- Add instrumentation and targeted fixes only.
- Keep all changes reversible behind feature flags where relevant.

========================================================
PHASE 1 — FIND THE REAL PUBLISH FAILURE (REQUIRED)
========================================================
1) Identify where publish fails:
- Check Replit Deploy/Publish logs (build logs + run logs).
- Capture the FIRST actual error stack/exit code (not perf warnings).
- Confirm which command Replit is running for:
  - build command
  - start command
  - health check path + timeout
- Confirm runtime port binding:
  - ensure server listens on process.env.PORT and 0.0.0.0

2) Add startup logging (safe):
At server boot, log:
- NODE_ENV
- PORT
- commit/version if available
- “server listening on host:port”
Make sure logs do not leak secrets.

3) Validate build artifacts:
- If using Vite/React: ensure build output exists and server serves it correctly.
- If monorepo: confirm correct workspace build order.

4) Validate migrations:
- If deploy runs migrations automatically, confirm they succeed.
- Add safe guard: migrations are idempotent and do not block startup indefinitely.

STOP and report the real publish error once found (in logs), and only then apply fixes below.

========================================================
PHASE 2 — HEALTH CHECK STABILITY (LIKELY PUBLISH BLOCKER)
========================================================
Replit deploy commonly fails if health checks time out.

1) Confirm what endpoint is used for health checks.
- If none exists, add: GET /healthz (public, no auth)
Return:
{ ok: true, ts: new Date().toISOString() }
Must be fast (<10ms), no DB access.

2) Ensure /healthz is registered early and never depends on DB.
3) If any middleware is causing delays globally (auth/tenant resolution), bypass it for /healthz.

========================================================
PHASE 3 — FIX /unread-count HOTSPOT (TARGETED)
========================================================
We are seeing frequent polling and 350–470ms responses. This can create load and may affect deploy stability.

1) Locate the /unread-count route handler and its query.
- Add timing breakdown logs (dev-only):
  - auth/tenant resolution ms
  - DB query ms
  - serialization ms

2) Optimize query shape:
- Ensure it is ONE aggregated query (COUNT) scoped by tenantId + userId.
- Add/verify indexes needed for unread counts (examples—match your schema):
  - messages/notifications table: (tenant_id, user_id, is_read, created_at)
  - or (tenant_id, user_id, read_at) depending on design

3) Add short TTL caching (SAFE)
- In-memory per-process cache (LRU map) keyed by tenantId:userId for 2–5 seconds.
- Only for /unread-count.
- Must respect tenant/user scoping.
- Add env flag: ENABLE_UNREAD_COUNT_CACHE default true in prod.

4) Reduce client polling (SAFE UI change)
- Find where UI calls /unread-count.
- If it polls every few seconds, slow it down:
  - active tab: 15–30s
  - background tab: pause or 60s+
- If you already have websockets/real-time notifications, prefer push updates.
- Keep polling as fallback.

========================================================
PHASE 4 — /timer/start 409 (NOT PUBLISH BLOCKER, BUT CLEANUP)
========================================================
A 409 likely means “timer already running” or conflict.
- Confirm server returns 409 intentionally.
- Ensure client handles 409 gracefully (show “timer already running” and sync state).
- Do not change behavior unless it’s incorrect.

========================================================
PHASE 5 — BUILD/START COMMAND HARDENING (COMMON REPLIT ISSUES)
========================================================
1) Confirm package scripts:
- "build" produces frontend assets + server build (if TS compiled)
- "start" runs the correct server entrypoint

2) Ensure Node version compatibility:
- If recent prompts introduced a package requiring newer Node, pin Node engine or adjust dependency.
- Run: npm ls (or pnpm/yarn equivalent) to find install errors.

3) Ensure no TypeScript build errors are being swallowed:
- Run typecheck in build pipeline and fail fast with clear output.

========================================================
PHASE 6 — APP DOCS UPDATE (MANDATORY)
========================================================
Add section: “Deploy/Pub Troubleshooting”
Include:
- healthz endpoint
- port binding rules
- common failure modes (migrations, build, memory)
- unread-count caching + polling strategy

========================================================
DELIVERABLES / STOP CONDITION
========================================================
- Identify the TRUE publish failure error from deploy logs and fix it.
- Add /healthz and ensure deploy health checks pass.
- Optimize /unread-count (query + index + short TTL cache + reduced polling).
- Ensure server binds to 0.0.0.0:${PORT}.
- Docs updated.

IMPORTANT:
Do not proceed with other refactors until publish is stable.